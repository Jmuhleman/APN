{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latin-founder",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"Logo HEIG-VD\" style=\"width: 80px;\" align=\"right\"/>\n",
    "\n",
    "# Cours APN - Labo 7 : Classification non supervisée\n",
    "\n",
    "## Résumé\n",
    "Le but de ce laboratoire est de réaliser une expérience de classification non-supervisée d'articles.  L'approche se base sur des vecteurs en basse dimension (*embeddings*) qui représentent les classes, qui seront comparés avec les vecteurs en basse dimension (*embeddings*) représentant les documents.  Ces *embeddings* seront obtenus soit au modèle `word2vec`.  La méthode sera testée sur un corpus d'articles provenant de rubriques connues, ce qui permettra d'évaluer les méthodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "perceived-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies générales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "moved-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarité entre vecteurs (mots, catégories ou textes)\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accepted-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies pour l'évaluation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-scanning",
   "metadata": {},
   "source": [
    "## 1. Préparation des données\n",
    "\n",
    "Vous utiliserez un corpus d'environ 200'000 articles (titres et résumés) [diponibles sur Kaggle](https://www.kaggle.com/datasets/rmisra/news-category-dataset/versions/2) (V2, 80 Mo, nécessite un login) mais dont une copie est **fournie sur Cyberlearn**.  Dans cette partie, vous allez:\n",
    "  - a. charger le corpus fourni au format JSON, l'explorer et afficher des statistiques\n",
    "  - b. définir une fonction de normalisation de textes (avec la librairie `utils.py` déjà utilisée)\n",
    "  - c. définir une fonction d'extraction des textes avec leur catégorie\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-raising",
   "metadata": {},
   "source": [
    "**a.** Veuillez charger le corpus à l'aide des instructions données ci-dessous, puis afficher les statistiques suivantes :\n",
    "  * un exemple d'article\n",
    "  * nombre total d'articles\n",
    "  * nombre d'articles pour chaque catégorie (ou classe) par ordre décroissant\n",
    "  * nombre d'articles sans `headline`\n",
    "  * nombre d'articles sans `short_description`\n",
    "  * nombre d'articles dont la longueur de `headline + short_description` est inférieure ou égale à 2 caractères\n",
    "  * longueur moyenne de `headline + short_description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aerial-integrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d'articles : 200853\n",
      "\n",
      "Exemple d'article : {'category': 'CRIME', 'headline': 'There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV', 'authors': 'Melissa Jeltsen', 'link': 'https://www.huffingtonpost.com/entry/texas-amanda-painter-mass-shooting_us_5b081ab4e4b0802d69caad89', 'short_description': 'She left her husband. He killed their children. Just another day in America.', 'date': '2018-05-26'}\n",
      "\n",
      "Nombre d'articles par catégorie\n",
      "POLITICS: 32739\n",
      "WELLNESS: 17827\n",
      "ENTERTAINMENT: 16058\n",
      "TRAVEL: 9887\n",
      "STYLE & BEAUTY: 9649\n",
      "PARENTING: 8677\n",
      "HEALTHY LIVING: 6694\n",
      "QUEER VOICES: 6314\n",
      "FOOD & DRINK: 6226\n",
      "BUSINESS: 5937\n",
      "COMEDY: 5175\n",
      "SPORTS: 4884\n",
      "BLACK VOICES: 4528\n",
      "HOME & LIVING: 4195\n",
      "PARENTS: 3955\n",
      "THE WORLDPOST: 3664\n",
      "WEDDINGS: 3651\n",
      "WOMEN: 3490\n",
      "IMPACT: 3459\n",
      "DIVORCE: 3426\n",
      "CRIME: 3405\n",
      "MEDIA: 2815\n",
      "WEIRD NEWS: 2670\n",
      "GREEN: 2622\n",
      "WORLDPOST: 2579\n",
      "RELIGION: 2556\n",
      "STYLE: 2254\n",
      "SCIENCE: 2178\n",
      "WORLD NEWS: 2177\n",
      "TASTE: 2096\n",
      "TECH: 2082\n",
      "MONEY: 1707\n",
      "ARTS: 1509\n",
      "FIFTY: 1401\n",
      "GOOD NEWS: 1398\n",
      "ARTS & CULTURE: 1339\n",
      "ENVIRONMENT: 1323\n",
      "COLLEGE: 1144\n",
      "LATINO VOICES: 1129\n",
      "CULTURE & ARTS: 1030\n",
      "EDUCATION: 1004\n",
      "\n",
      "Nombre d'articles sans 'headline' : 6\n",
      "Nombre d'articles sans 'short_description' : 19712\n",
      "Nombre d'articles avec 'headline + short_description' ≤ 2 caractères : 5\n",
      "Longueur moyenne de 'headline + short_description' : 172.25\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter # pour calculer facilement le nombre d'articles par categorie\n",
    "\n",
    "file_path = './News_Category_Dataset_v2.json/News_Category_Dataset_v2.json'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "total_articles = len(data)\n",
    "print(f\"Nombre total d'articles : {total_articles}\")\n",
    "\n",
    "\n",
    "example_article = data[0]\n",
    "print(\"\\nExemple d'article :\", example_article)\n",
    "\n",
    "categories = [article['category'] for article in data if 'category' in article]\n",
    "category_counts = Counter(categories)\n",
    "print(\"\\nNombre d'articles par catégorie\")\n",
    "for category, count in category_counts.most_common():\n",
    "    print(f\"{category}: {count}\")\n",
    "\n",
    "missing_headlines = sum(1 for article in data if not article.get('headline'))\n",
    "print(f\"\\nNombre d'articles sans 'headline' : {missing_headlines}\")\n",
    "\n",
    "missing_descriptions = sum(1 for article in data if not article.get('short_description'))\n",
    "print(f\"Nombre d'articles sans 'short_description' : {missing_descriptions}\")\n",
    "\n",
    "short_articles = sum(\n",
    "    1 for article in data if len(article.get('headline', '') + article.get('short_description', '')) <= 2\n",
    ")\n",
    "print(f\"Nombre d'articles avec 'headline + short_description' ≤ 2 caractères : {short_articles}\")\n",
    "\n",
    "total_length = sum(\n",
    "    len(article.get('headline', '') + article.get('short_description', '')) for article in data\n",
    ")\n",
    "average_length = total_length / total_articles\n",
    "print(f\"Longueur moyenne de 'headline + short_description' : {average_length:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0afe177",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mineral-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus  = []\n",
    "with open('News_Category_Dataset_v2.json/News_Category_Dataset_v2.json', mode='r', errors='ignore') as json_file:\n",
    "    for dic in json_file:\n",
    "        corpus.append(json.loads(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-bookmark",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aerial-gates",
   "metadata": {},
   "source": [
    "**b.** Veuillez définir une fonction de nettoyage et normalisation des textes, qui vise à réduire la diversité du vocabulaire (lemmatisation, suppression des ponctuations, nombres, ou *stopwords*, etc.).  Veuillez utiliser les fonctions fournies dans la librairie `utils.py` fournie sur Cyberlearn et déjà vue au labo 3 (groupement hiérarchique de films).  Votre fonction devra prendre en entrée un texte non-tokenisé (une chaîne de caractères) et retournera une chaîne de caractères également, mais avec tous les tokens retenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "little-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bottom-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    texte = utils.remove_punctuation(text)\n",
    "    texte = utils.remove_non_alphabetic(texte)\n",
    "    texte = utils.lemmatize_text(texte)\n",
    "    texte = utils.remove_stopwords(texte)\n",
    "    \n",
    "    return texte "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-supervisor",
   "metadata": {},
   "source": [
    "**c.** Veuillez écrire une fonction qui sélectionne les articles d'une ou plusieurs catégories (données sous forme de liste, p.ex. `['MONEY', 'SCIENCE']`) et retourne leurs textes et leurs catégories.  Plus précisément :\n",
    "* la fonction retourne une liste de textes et une liste de catégories de même longueur (au texte *i* correspond la catégorie ou classe *i*)\n",
    "* le texte de chaque article est composé de son `headline` et de sa `short_description`, séparés par un point+espace\n",
    "* si `normalize=True`, la fonction normalise les textes (note : ça ne sera pas toujours souhaitable dans les expériences suivantes)\n",
    "* on ne retient dans le résultat que les textes dont la longueur finale est supérieure à 3 caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "secret-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_texts_categories(corpus, selected_categories, normalize=True):\n",
    "    texts = []\n",
    "    categories = []\n",
    "\n",
    "    for article in corpus:\n",
    "\n",
    "        if article.get('category') in selected_categories:\n",
    "            headline = article.get('headline', '').strip()\n",
    "            short_description = article.get('short_description', '').strip()\n",
    "            text = f\"{headline}. {short_description}\" if headline or short_description else \"\"\n",
    "            \n",
    "            if normalize and text:\n",
    "                text = normalize_text(text)\n",
    "            \n",
    "            if len(text) > 3:\n",
    "                texts.append(text)\n",
    "                categories.append(article['category'])\n",
    "    \n",
    "    return texts, categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-research",
   "metadata": {},
   "source": [
    "**d.** Veuillez exécuter la fonction, en appliquant la normalisation des textes, puis afficher un exemple de résultat et commenter brièvement son contenu.  Le code est donné ci-dessous, et vous devez ajouter votre commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "directed-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_categories = ['MONEY', 'SCIENCE']\n",
    "texts, categories = select_texts_categories(corpus, selected_categories, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be386bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple : SCIENCE : fireball rip siberian sky brilliant display light frankly scar think bomb witness\n"
     ]
    }
   ],
   "source": [
    "print(\"Exemple :\", categories[142], ':', texts[142])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03cdd238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre commentaire ici.\n",
    "# Nous pouvons voir que le texte normalisé est exempt de \"\" ou autres signes de ponctuations.\n",
    "# Nous remarquons que les mots sémantiquement importants sont conservés comme dans l'exemple ci-dessus.\n",
    "# La lemmatisation est également effectuées puisque nous voyons des mots comme \"scar\". \n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-tampa",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Classification non supervisée avec des embeddings word2vec\n",
    "\n",
    "La méthode de classification proposée comporte trois étapes.  Le but de cette partie est de définir une fonction pour chacune d'elles.  Au début, une (re)prise en main de word2vec est demandée.\n",
    "* a. prise en main de word2vec\n",
    "* b. création des représentations vectorielles (*embeddings*) des classes (catégories)\n",
    "* c. création des représentations vectorielles (*embeddings*) d'un texte\n",
    "* d. classification : comparer les similarités du vecteur de texte avec les vecteurs des classes, choisir la plus similaire\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-trustee",
   "metadata": {},
   "source": [
    "**a.** Prise en main de word2vec.  Vous avez déjà utilisé word2vec au Labo 4 sur la visualisation de vecteurs de mots (et Cémantix) mais ici vous utiliserez un modèle pour l'anglais.  Vous pouvez consulter la [documentation de gensim sur KeyedVectors](https://radimrehurek.com/gensim/models/keyedvectors.html#what-can-i-do-with-word-vectors)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "available-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "different-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si le modèle n'est pas téléchargé :\n",
    "#w2v_model = gensim.downloader.load('word2vec-google-news-300')\n",
    "# S'il l'est déjà, indiquer son emplacement :\n",
    "path_to_model = \"C:\\\\Users\\\\Julien\\\\gensim-data\\\\word2vec-google-news-300\\\\word2vec-google-news-300.gz\"\n",
    "w2v_model = KeyedVectors.load_word2vec_format(path_to_model, binary=True, unicode_errors=\"ignore\")\n",
    "# Attention, ce modèle prend environ 5 Go en mémoire. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-tournament",
   "metadata": {},
   "source": [
    "Veuillez afficher les mots les plus similaires selon ce modèle word2vec du mot 'science'.  Même question pour le mot 'money' (ce sont des noms de catégories).  Que pensez-vous du résultat ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "australian-newman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots similaires à 'science' :\n",
      "faith_Jezierski: 0.6965\n",
      "sciences: 0.6821\n",
      "biology: 0.6776\n",
      "scientific: 0.6535\n",
      "mathematics: 0.6301\n",
      "Hilal_Khashan_professor: 0.6153\n",
      "impeach_USADA: 0.6149\n",
      "professor_Kent_Redfield: 0.6144\n",
      "physics_astronomy: 0.6105\n",
      "bionic_prosthetic_fingers: 0.6083\n",
      "\n",
      "Mots similaires à 'money' :\n",
      "monies: 0.7165\n",
      "funds: 0.7055\n",
      "moneys: 0.6289\n",
      "dollars: 0.6289\n",
      "cash: 0.6151\n",
      "vast_sums: 0.6057\n",
      "fund: 0.5790\n",
      "Money: 0.5733\n",
      "taxpayer_dollars: 0.5694\n",
      "Monies: 0.5587\n"
     ]
    }
   ],
   "source": [
    "similar_to_science = w2v_model.most_similar(\"science\", topn=10)\n",
    "print(\"Mots similaires à 'science' :\")\n",
    "for word, similarity in similar_to_science:\n",
    "    print(f\"{word}: {similarity:.4f}\")\n",
    "\n",
    "similar_to_money = w2v_model.most_similar(\"money\", topn=10)\n",
    "print(\"\\nMots similaires à 'money' :\")\n",
    "for word, similarity in similar_to_money:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-diana",
   "metadata": {},
   "source": [
    "Basé sur les résultats précédents et vos intuitions sur les articles qu'on peut trouver dans les catégories `['SCIENCE', 'MONEY']`, veuillez indiquer ici 5 à 10 mots représentatifs de chacune de ces deux catégories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f3ac90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155       The researchers plan to scour the Loch Ness ne...\n",
       "285       The supposed \"interstellar immigrant\" is locat...\n",
       "439       It's the first time a rocket designed by a Chi...\n",
       "449                                                  YIKES!\n",
       "1246      Some of America's top researchers will move to...\n",
       "                                ...                        \n",
       "200754    Because of the overuse of antibiotics, antibio...\n",
       "200815    Gallery: Space Station's Expedition 30 Mission...\n",
       "200816    image 1: throw As Hizook reports, DLR started ...\n",
       "200817    That doesn't mean Jobs lacks for fans in the w...\n",
       "200818    Aurora borealis can typically only be seen at ...\n",
       "Name: short_description, Length: 3885, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[ data_df['category'].isin(['MONEY', 'SCIENCE']) ]['short_description']\n",
    "#\n",
    "# Nous pouvons citer les mots similaires à 'science' : biology, sciences, scientific, chemistry, physics, neuroscience, mathematics, biochemistry, biophysics, et biotechnology.\n",
    "\n",
    "# Nous pouvons citer les mots similaires à 'money' : cash, dollars, money, funds, currency, euros, million, billions, and trillions.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-macintosh",
   "metadata": {},
   "source": [
    "**b.** Création des représentations vectorielles des classes (catégories).\n",
    "\n",
    "Veuillez définir une fonction qui retourne un vecteur (*embedding*) word2vec pour chacune des classes d'un tableau qui est fourni en argument de la fonction.  Consignes :\n",
    "\n",
    "* la fonction retourne la moyenne des *embeddings* des mots-clés associés à chaque classe;\n",
    "* pour les classes 'SCIENCE' et 'MONEY', elle prend les mots-clés que vous avez choisis ci-dessus (au (a)) ;\n",
    "* pour les autres classes, elle demande à word2vec les `topn` voisins du nom de la classe (en minuscules) ;\n",
    "  - si `topn = 0`, on utilise seulement le nom de la classe (en minuscules) ;\n",
    "  - on suppose que le nom de la classe est connu de word2vec.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "empty-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def cat_embedding_w2v(model, category_names, topn=30):\n",
    "\n",
    "    category_embeddings = {}\n",
    "    \n",
    "    # Mots-clés pour SCIENCE et MONEY\n",
    "    category_keywords = {\n",
    "        'SCIENCE': [\"research\", \"technology\", \"experiment\", \"discovery\", \"biology\", \"physics\", \"chemistry\", \"innovation\", \"astronomy\", \"data\"],\n",
    "        'MONEY': [\"finance\", \"investment\", \"market\", \"currency\", \"stock\", \"wealth\", \"cash\", \"banking\", \"economy\", \"business\"]\n",
    "    }\n",
    "    \n",
    "    for category in category_names:\n",
    "\n",
    "        if category in category_keywords:\n",
    "            words = category_keywords[category]\n",
    "        else:\n",
    "            # Sinon, récupérer les voisins du nom de la catégorie\n",
    "            words = [category.lower()]\n",
    "            if topn > 0:\n",
    "                try:\n",
    "                    # Récupérer les mots les plus proches du nom de la catégorie\n",
    "                    similar_words = model.most_similar(category.lower(), topn=topn)\n",
    "                    words.extend([word for word, _ in similar_words])\n",
    "                except KeyError:\n",
    "                    print(f\"Le mot '{category.lower()}' n'a pas été trouvé dans le vocabulaire du modèle.\")\n",
    "\n",
    "        # Calculer la moyenne des embeddings des mots\n",
    "        embeddings = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                embeddings.append(model[word])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        # Calculer la moyenne des embeddings\n",
    "        if embeddings:\n",
    "            category_embeddings[category] = np.mean(embeddings, axis=0)\n",
    "        else:\n",
    "            category_embeddings[category] = np.zeros(model.vector_size)\n",
    "    return category_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "three-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]]\n"
     ]
    }
   ],
   "source": [
    "# Test : affiche-t-on 'True' ?\n",
    "# faire un array depuis le dictionnaire\n",
    "e1 = np.array(cat_embedding_w2v(w2v_model, ['SCIENCE'], topn=30)['SCIENCE'])\n",
    "e2 = np.array(cat_embedding_w2v(w2v_model, ['TECH'], topn=30)['TECH'])\n",
    "e3 = np.array(cat_embedding_w2v(w2v_model, ['TASTE'], topn=30)['TASTE'])\n",
    "\n",
    "e1 = e1.reshape(1, -1)\n",
    "e2 = e2.reshape(1, -1)\n",
    "e3 = e3.reshape(1, -1)\n",
    "\n",
    "result = cosine_similarity(e1, e2) > cosine_similarity(e2, e3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-journal",
   "metadata": {},
   "source": [
    "**c.** Création de la représentation vectorielle d'un texte\n",
    "\n",
    "Veuillez définir une fonction qui prend un texte (*string*) en argument et retourne un vecteur (*embedding*) qui représente le texte.  Le texte doit être découpé en mots (tokenisé), puis on doit tester si chaque mot est connu du modèle word2vec, et si oui, on récupère le *embedding* du mot.  La fonction retourne la moyenne des *embeddings*, sauf si aucun mot du texte n'est connu du modèle word2vec, auquel cas elle retourne `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "thick-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "asian-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embedding_w2v(model, text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    embeddings = []\n",
    "    \n",
    "    for word in words:\n",
    "        try:\n",
    "            # Tente d'accéder à l'embedding du mot\n",
    "            embeddings.append(model[word])\n",
    "        except KeyError:\n",
    "            # Si le mot n'est pas trouvé dans le vocabulaire du modèle, on l'ignore\n",
    "            continue\n",
    "    \n",
    "    # Si au moins un mot connu est trouvé, on retourne la moyenne des embeddings\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return []  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-samoa",
   "metadata": {},
   "source": [
    "**d.** Classification non supervisée d'articles avec word2vec\n",
    "\n",
    "Veuillez définir une fonction qui prend en entrée :\n",
    "* un modèle word2vec\n",
    "* une liste de textes à classifier\n",
    "* une liste de catégories définies par leur nom en majuscules (p.ex. `['SCIENCE', 'MONEY']`)\n",
    "et qui retourne le tableau avec la catégorie prédite pour chaque texte parmi les catégories données.  \n",
    "\n",
    "Pour prédire la catégorie, la fonction calcule la similarité cosinus du *embedding* du texte avec chacun des *embeddings* des catégories, et choisit la catégorie qui a la plus grande similarité.  Si le texte n'a pas de *embedding* (parce qu'aucun de ses mots n'est connu du modèle), ou si plusieurs catégories ont la même similarité, on tire au sort la catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "compatible-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import random\n",
    "\n",
    "def classify_w2v(model, texts, selected_categories, topn = 30):\n",
    "\n",
    "    category_embeddings = cat_embedding_w2v(model, selected_categories, topn)\n",
    "    cat_pred = []\n",
    "\n",
    "    for text in texts:\n",
    "        text_embedding = text_embedding_w2v(model, text)\n",
    "        \n",
    "        if len(text_embedding) == 0:\n",
    "            # Si aucun embedding n'est trouvé, tirer une catégorie au sort\n",
    "            predicted_category = random.choice(selected_categories)\n",
    "        else:\n",
    "            # Calculer la similarité cosinus entre le texte et chaque catégorie\n",
    "            similarities = {}\n",
    "            for category, category_embedding in category_embeddings.items():\n",
    "                if np.linalg.norm(category_embedding) != 0:\n",
    "                    similarity = 1 - cosine(text_embedding, category_embedding)\n",
    "                else:\n",
    "                    similarity = -1\n",
    "                similarities[category] = similarity\n",
    "            \n",
    "            max_similarity = max(similarities.values())\n",
    "            best_categories = [cat for cat, sim in similarities.items() if sim == max_similarity]\n",
    "            \n",
    "            predicted_category = random.choice(best_categories)\n",
    "        \n",
    "        cat_pred.append(predicted_category)\n",
    "    \n",
    "    return cat_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-river",
   "metadata": {},
   "source": [
    "**e.** Veuillez réaliser la classification non supervisée des articles des catégories `['SCIENCE', 'MONEY']`.  Afficher les scores obtenus et la matrice de confusion en utilisant les fonctions de `sklearn.metrics` importées au début du notebook.  Veuillez faire plusieurs essais pour optimiser les fonctions et leurs appels, et à la fin laisser votre meilleur résultat dans ce notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "african-airport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitude : 0.9297297297297298\n",
      "Matrice de confusion :\n",
      "[[2026  152]\n",
      " [ 121 1586]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     SCIENCE       0.94      0.93      0.94      2178\n",
      "       MONEY       0.91      0.93      0.92      1707\n",
      "\n",
      "    accuracy                           0.93      3885\n",
      "   macro avg       0.93      0.93      0.93      3885\n",
      "weighted avg       0.93      0.93      0.93      3885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "selected_categories = ['SCIENCE', 'MONEY']\n",
    "texts, categories = select_texts_categories(corpus, selected_categories, normalize=True)\n",
    "\n",
    "predicted_categories = classify_w2v(w2v_model, texts, categories, topn=30)\n",
    "predicted_categories_filtered = predicted_categories[:len(categories)]\n",
    "\n",
    "accuracy = accuracy_score(categories, predicted_categories_filtered)\n",
    "conf_matrix = confusion_matrix(categories, predicted_categories_filtered, labels=selected_categories)\n",
    "class_report = classification_report(categories, predicted_categories_filtered, labels=selected_categories)\n",
    "\n",
    "print(f\"Exactitude : {accuracy}\")\n",
    "print(f\"Matrice de confusion :\\n{conf_matrix}\")\n",
    "print(f\"Rapport de classification :\\n{class_report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-livestock",
   "metadata": {},
   "source": [
    "**f.** Veuillez réaliser une expérience de classification non supervisée sur les articles des catégories `['TECH', 'ARTS', 'COLLEGE']` en variant le paramètre `topn` de `classify_w2v` et en indiquant la meilleure valeur trouvée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8967330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3885"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c3f95b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topn: 10\n",
      "Accuracy: 0.7852164730728617\n",
      "Confusion Matrix:\n",
      "[[1738   79  265]\n",
      " [ 262  983  264]\n",
      " [  79   68  997]]\n",
      "Topn: 20\n",
      "Accuracy: 0.8101372756071805\n",
      "Confusion Matrix:\n",
      "[[1880   77  125]\n",
      " [ 334 1027  148]\n",
      " [ 140   75  929]]\n",
      "Topn: 30\n",
      "Accuracy: 0.7788806758183738\n",
      "Confusion Matrix:\n",
      "[[1811   39  232]\n",
      " [ 365  853  291]\n",
      " [  90   30 1024]]\n",
      "\n",
      "Meilleur topn: 20\n",
      "Meilleure précision: 0.8101372756071805\n",
      "Matrice de confusion pour topn = 20:\n",
      "[[1880   77  125]\n",
      " [ 334 1027  148]\n",
      " [ 140   75  929]]\n",
      "\n",
      "Rapport de classification pour topn = 20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        TECH       0.80      0.90      0.85      2082\n",
      "        ARTS       0.87      0.68      0.76      1509\n",
      "     COLLEGE       0.77      0.81      0.79      1144\n",
      "\n",
      "    accuracy                           0.81      4735\n",
      "   macro avg       0.81      0.80      0.80      4735\n",
      "weighted avg       0.82      0.81      0.81      4735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "selected_categories = ['TECH', 'ARTS', 'COLLEGE']\n",
    "texts, categories = select_texts_categories(corpus, selected_categories, normalize=False)\n",
    "\n",
    "topn_values = [10, 20, 30]\n",
    "best_topn = None\n",
    "best_accuracy = 0\n",
    "best_confusion_matrix = None\n",
    "\n",
    "for topn in topn_values:\n",
    "    predicted_categories = classify_w2v(w2v_model, texts, selected_categories, topn=topn)\n",
    "    predicted_categories_filtered = predicted_categories[:len(categories)]\n",
    "\n",
    "    accuracy = accuracy_score(categories, predicted_categories_filtered)\n",
    "    conf_matrix = confusion_matrix(categories, predicted_categories_filtered, labels=selected_categories)\n",
    "\n",
    "    print(f\"Topn: {topn}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_topn = topn\n",
    "        best_confusion_matrix = conf_matrix\n",
    "\n",
    "print(f\"\\nMeilleur topn: {best_topn}\")\n",
    "print(f\"Meilleure précision: {best_accuracy}\")\n",
    "print(f\"Matrice de confusion pour topn = {best_topn}:\\n{best_confusion_matrix}\")\n",
    "\n",
    "predicted_categories_final = classify_w2v(w2v_model, texts, selected_categories, topn=best_topn)\n",
    "predicted_categories_filtered_final = predicted_categories_final[:len(categories)]\n",
    "\n",
    "class_report = classification_report(categories, predicted_categories_filtered_final, labels=selected_categories)\n",
    "print(f\"\\nRapport de classification pour topn = {best_topn}:\\n{class_report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-elizabeth",
   "metadata": {},
   "source": [
    "**g.** Veuillez comparer les deux expériences (points (e) et (f)) en termes de scores, de valeurs optimales de `topn`, et de l'impact du nettoyage de textes.   Veuillez donner votre opinion sur la qualité de la classification non supervisée avec word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb83f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "improving-drunk",
   "metadata": {},
   "source": [
    "**Fin du Labo.**  Veuillez nettoyer ce notebook en gardant seulement les résultats et les commentaires demandés, l'enregistrer, et le soumettre comme devoir sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
